{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-05-13 23:28:07</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:15.22        </td></tr>\n",
       "<tr><td>Memory:      </td><td>43.8/125.7 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/48 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 3<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_None_5cb3c_00000</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_23-25-26_109564_40706/artifacts/2024-05-13_23-27-51/PPO_2024-05-13_23-27-51/driver_artifacts/PPO_None_5cb3c_00000_0_lr=0.0100_2024-05-13_23-27-51/error.txt</td></tr>\n",
       "<tr><td>PPO_None_5cb3c_00001</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_23-25-26_109564_40706/artifacts/2024-05-13_23-27-51/PPO_2024-05-13_23-27-51/driver_artifacts/PPO_None_5cb3c_00001_1_lr=0.0010_2024-05-13_23-27-51/error.txt</td></tr>\n",
       "<tr><td>PPO_None_5cb3c_00002</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-05-13_23-25-26_109564_40706/artifacts/2024-05-13_23-27-51/PPO_2024-05-13_23-27-51/driver_artifacts/PPO_None_5cb3c_00002_2_lr=0.0001_2024-05-13_23-27-51/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name          </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_None_5cb3c_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.01  </td></tr>\n",
       "<tr><td>PPO_None_5cb3c_00001</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.001 </td></tr>\n",
       "<tr><td>PPO_None_5cb3c_00002</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.0001</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 23:28:06,658\tERROR tune_controller.py:1331 -- Trial task failed for trial PPO_None_5cb3c_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=10559, ip=10.16.20.158, actor_id=42d59f4a36665d47eee3e5a501000000, repr=PPO)\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py\", line 239, in _setup\n",
      "    self.add_workers(\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py\", line 754, in add_workers\n",
      "    raise result.get()\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py\", line 497, in _fetch_result\n",
      "    result = ray.get(r)\n",
      "             ^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=18460, ip=10.16.20.158, actor_id=21580ca752b7d430e623b3c701000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fc8cbe450d0>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 477, in __init__\n",
      "    self.policy_dict, self.is_policy_to_train = self.config.get_multi_agent_setup(\n",
      "                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm_config.py\", line 3316, in get_multi_agent_setup\n",
      "    raise ValueError(\n",
      "ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::PPO.__init__()\u001b[39m (pid=10559, ip=10.16.20.158, actor_id=42d59f4a36665d47eee3e5a501000000, repr=PPO)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py\", line 554, in __init__\n",
      "    super().__init__(\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py\", line 640, in setup\n",
      "    self.workers = EnvRunnerGroup(\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py\", line 191, in __init__\n",
      "    raise e.args[0].args[2]\n",
      "ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
      "2024-05-13 23:28:06,787\tERROR tune_controller.py:1331 -- Trial task failed for trial PPO_None_5cb3c_00002\n",
      "Traceback (most recent call last):\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=10576, ip=10.16.20.158, actor_id=dd93f32e481a46a92167459501000000, repr=PPO)\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py\", line 239, in _setup\n",
      "    self.add_workers(\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py\", line 754, in add_workers\n",
      "    raise result.get()\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py\", line 497, in _fetch_result\n",
      "    result = ray.get(r)\n",
      "             ^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=18426, ip=10.16.20.158, actor_id=7fe2498116f3d9e0bfefde4f01000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7f00e40edcd0>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 477, in __init__\n",
      "    self.policy_dict, self.is_policy_to_train = self.config.get_multi_agent_setup(\n",
      "                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm_config.py\", line 3316, in get_multi_agent_setup\n",
      "    raise ValueError(\n",
      "ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::PPO.__init__()\u001b[39m (pid=10576, ip=10.16.20.158, actor_id=dd93f32e481a46a92167459501000000, repr=PPO)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py\", line 554, in __init__\n",
      "    super().__init__(\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py\", line 640, in setup\n",
      "    self.workers = EnvRunnerGroup(\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py\", line 191, in __init__\n",
      "    raise e.args[0].args[2]\n",
      "ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
      "2024-05-13 23:28:07,005\tERROR tune_controller.py:1331 -- Trial task failed for trial PPO_None_5cb3c_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/_private/worker.py\", line 2623, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/_private/worker.py\", line 863, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=10566, ip=10.16.20.158, actor_id=8bd70aff04ebee743c725e3a01000000, repr=PPO)\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py\", line 239, in _setup\n",
      "    self.add_workers(\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py\", line 754, in add_workers\n",
      "    raise result.get()\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py\", line 497, in _fetch_result\n",
      "    result = ray.get(r)\n",
      "             ^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::RolloutWorker.__init__()\u001b[39m (pid=18738, ip=10.16.20.158, actor_id=cff4884207eff91e7033fe7e01000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7fb47ae92410>)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 477, in __init__\n",
      "    self.policy_dict, self.is_policy_to_train = self.config.get_multi_agent_setup(\n",
      "                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm_config.py\", line 3316, in get_multi_agent_setup\n",
      "    raise ValueError(\n",
      "ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::PPO.__init__()\u001b[39m (pid=10566, ip=10.16.20.158, actor_id=8bd70aff04ebee743c725e3a01000000, repr=PPO)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py\", line 554, in __init__\n",
      "    super().__init__(\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 158, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py\", line 640, in setup\n",
      "    self.workers = EnvRunnerGroup(\n",
      "                   ^^^^^^^^^^^^^^^\n",
      "  File \"/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/env/env_runner_group.py\", line 191, in __init__\n",
      "    raise e.args[0].args[2]\n",
      "ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!\n",
      "2024-05-13 23:28:07,021\tWARNING experiment_state.py:205 -- Experiment state snapshotting has been triggered multiple times in the last 5.0 seconds. A snapshot is forced if `CheckpointConfig(num_to_keep)` is set, and a trial has checkpointed >= `num_to_keep` times since the last snapshot.\n",
      "You may want to consider increasing the `CheckpointConfig(num_to_keep)` or decreasing the frequency of saving checkpoints.\n",
      "You can suppress this error by setting the environment variable TUNE_WARN_EXCESSIVE_EXPERIMENT_CHECKPOINT_SYNC_THRESHOLD_S to a smaller value than the current threshold (5.0).\n",
      "2024-05-13 23:28:07,024\tINFO tune.py:1007 -- Wrote the latest version of all result files and experiment state to '/home/jianghaoning/ray_results/PPO_2024-05-13_23-27-51' in 0.0146s.\n",
      "2024-05-13 23:28:07,032\tERROR tune.py:1035 -- Trials did not complete: [PPO_None_5cb3c_00000, PPO_None_5cb3c_00001, PPO_None_5cb3c_00002]\n",
      "2024-05-13 23:28:07,033\tINFO tune.py:1039 -- Total run time: 15.27 seconds (15.20 seconds for the tuning loop).\n",
      "2024-05-13 23:28:07,062\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 3 trial(s):\n",
      "- PPO_None_5cb3c_00000: FileNotFoundError('Could not fetch metrics for PPO_None_5cb3c_00000: both result.json and progress.csv were not found at /home/jianghaoning/ray_results/PPO_2024-05-13_23-27-51/PPO_None_5cb3c_00000_0_lr=0.0100_2024-05-13_23-27-51')\n",
      "- PPO_None_5cb3c_00001: FileNotFoundError('Could not fetch metrics for PPO_None_5cb3c_00001: both result.json and progress.csv were not found at /home/jianghaoning/ray_results/PPO_2024-05-13_23-27-51/PPO_None_5cb3c_00001_1_lr=0.0010_2024-05-13_23-27-51')\n",
      "- PPO_None_5cb3c_00002: FileNotFoundError('Could not fetch metrics for PPO_None_5cb3c_00002: both result.json and progress.csv were not found at /home/jianghaoning/ray_results/PPO_2024-05-13_23-27-51/PPO_None_5cb3c_00002_2_lr=0.0001_2024-05-13_23-27-51')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResultGrid<[\n",
       "  Result(\n",
       "    error='ActorDiedError',\n",
       "    metrics={},\n",
       "    path='/home/jianghaoning/ray_results/PPO_2024-05-13_23-27-51/PPO_None_5cb3c_00000_0_lr=0.0100_2024-05-13_23-27-51',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    error='ActorDiedError',\n",
       "    metrics={},\n",
       "    path='/home/jianghaoning/ray_results/PPO_2024-05-13_23-27-51/PPO_None_5cb3c_00001_1_lr=0.0010_2024-05-13_23-27-51',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  ),\n",
       "  Result(\n",
       "    error='ActorDiedError',\n",
       "    metrics={},\n",
       "    path='/home/jianghaoning/ray_results/PPO_2024-05-13_23-27-51/PPO_None_5cb3c_00002_2_lr=0.0001_2024-05-13_23-27-51',\n",
       "    filesystem='local',\n",
       "    checkpoint=None\n",
       "  )\n",
       "]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "from ray import train, tune\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.tune.logger import pretty_print\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "config = PPOConfig().training(lr=tune.grid_search([0.01, 0.001, 0.0001]))\n",
    "\n",
    "tuner = tune.Tuner(\n",
    "    \"PPO\",\n",
    "    run_config=train.RunConfig(\n",
    "        stop={\"episode_reward_mean\": 150},\n",
    "    ),\n",
    "    param_space=config,\n",
    ")\n",
    "\n",
    "tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:521: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-05-13 23:42:18,915\tWARNING deprecation.py:50 -- DeprecationWarning: `WorkerSet(num_workers=... OR local_worker=...)` has been deprecated. Use `EnvRunnerGroup(num_env_runners=... AND local_env_runner=...)` instead. This will raise an error in the future!\n",
      "2024-05-13 23:42:18,916\tWARNING deprecation.py:50 -- DeprecationWarning: `max_num_worker_restarts` has been deprecated. Use `AlgorithmConfig.max_num_env_runner_restarts` instead. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/models/catalog.py:895: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  prep = cls(observation_space, options)\n",
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/connectors/agent/obs_preproc.py:37: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  self._preprocessor = get_preprocessor(obs_space)(\n",
      "2024-05-13 23:42:25,194\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "# Note: `gymnasium` (not `gym`) will be **the** API supported by RLlib from Ray 2.3 on.\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "\n",
    "    gymnasium = True\n",
    "except Exception:\n",
    "    import gym\n",
    "\n",
    "    gymnasium = False\n",
    "\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "env_name = \"CartPole-v1\"\n",
    "env = gym.make(env_name)\n",
    "algo = PPOConfig().environment(env_name).build()\n",
    "\n",
    "episode_reward = 0\n",
    "terminated = truncated = False\n",
    "\n",
    "if gymnasium:\n",
    "    obs, info = env.reset()\n",
    "else:\n",
    "    obs = env.reset()\n",
    "\n",
    "while not terminated and not truncated:\n",
    "    action = algo.compute_single_action(obs)\n",
    "    if gymnasium:\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "    else:\n",
    "        obs, reward, terminated, info = env.step(action)\n",
    "    episode_reward += reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何在RLlib中访问策略状态（policy state），即算法内部的状态，例如设置或获取模型权重等操作。\n",
    "\n",
    "首先，它指出RLlib算法的状态是在集群中的多个回滚工作者（Rollout Workers）之间复制的。回滚工作者是Ray的actor，负责执行环境交互和生成训练数据。然后，它介绍了两种方法来在调用train()之间轻松获取和更新此状态：\n",
    "\n",
    "使用Algorithm.workers.foreach_worker()或Algorithm.workers.foreach_worker_with_index()函数。这些函数接受一个lambda函数作为参数，并将其应用于每个回滚工作者。它们返回每个工作者的值列表，允许您在训练周期之间进行状态的传递和更新。\n",
    "\n",
    "通过Algorithm.get_policy()或Algorithm.workers.local_worker()访问算法状态的“主”副本。这允许您直接访问主副本的状态，但需要注意，对主副本的更新可能不会立即反映在回滚工作者上（如果您配置了num_env_runners > 0）。这意味着如果您在num_env_runners > 0的情况下进行了更新，可能需要一些时间才能在回滚工作者中看到更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 23:43:03,478\tWARNING deprecation.py:50 -- DeprecationWarning: `WorkerSet(num_workers=... OR local_worker=...)` has been deprecated. Use `EnvRunnerGroup(num_env_runners=... AND local_env_runner=...)` instead. This will raise an error in the future!\n",
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/algorithms/dqn/dqn_torch_model.py:61: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  super(DQNTorchModel, self).__init__(\n",
      "2024-05-13 23:43:03,768\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'_hidden_layers.0._model.0.weight': array([[-0.23787265, -0.32587072,  0.10094426, -0.9094147 ],\n",
       "         [ 0.46850386,  0.12140537,  0.38471243,  0.78597784],\n",
       "         [ 0.29163662, -0.21202134,  0.58655345,  0.7252241 ],\n",
       "         ...,\n",
       "         [-0.6381535 , -0.25386614, -0.36334828,  0.62951577],\n",
       "         [ 0.07889429,  0.9354121 ,  0.22815892,  0.25830847],\n",
       "         [ 0.60462385,  0.0169113 , -0.58495396, -0.54034513]],\n",
       "        dtype=float32),\n",
       "  '_hidden_layers.0._model.0.bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.], dtype=float32),\n",
       "  '_hidden_layers.1._model.0.weight': array([[ 0.00302477, -0.03765601, -0.02922693, ..., -0.02732067,\n",
       "          -0.01791365, -0.00040336],\n",
       "         [ 0.09348325, -0.00887662,  0.04243323, ..., -0.07775198,\n",
       "          -0.03767312,  0.02433942],\n",
       "         [-0.09886938,  0.02243485, -0.00649884, ...,  0.1256843 ,\n",
       "           0.03121376,  0.095121  ],\n",
       "         ...,\n",
       "         [ 0.09566151,  0.01647992, -0.03457767, ..., -0.01151218,\n",
       "          -0.050662  ,  0.1112742 ],\n",
       "         [-0.14504267,  0.0956035 ,  0.01976031, ...,  0.05847651,\n",
       "          -0.12044689,  0.10873015],\n",
       "         [-0.03718225, -0.05520067,  0.10277916, ...,  0.03073365,\n",
       "           0.01325693, -0.05957762]], dtype=float32),\n",
       "  '_hidden_layers.1._model.0.bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.], dtype=float32),\n",
       "  '_value_branch._model.0.weight': array([[-7.03709491e-04, -6.99215219e-04, -1.50715845e-04,\n",
       "           2.51619786e-04, -3.46299901e-04, -7.09265732e-05,\n",
       "          -1.21803103e-04, -3.41724285e-06,  1.56133343e-03,\n",
       "          -1.30109501e-03, -3.20631843e-05, -3.19757761e-04,\n",
       "           8.77097074e-04,  5.32679078e-05,  1.49004627e-03,\n",
       "          -1.75566660e-04, -5.44481562e-04, -1.40760400e-04,\n",
       "           3.16771795e-04, -4.07526735e-04,  7.43564218e-04,\n",
       "           6.32223018e-05,  6.71416754e-04,  4.60797950e-04,\n",
       "           4.61823976e-04, -4.16244438e-04,  9.48762463e-05,\n",
       "          -1.21013218e-05, -4.41626529e-04,  4.21610748e-04,\n",
       "          -3.93196096e-05,  1.88196762e-04,  2.05926422e-04,\n",
       "          -9.39318386e-04, -6.69862857e-05, -2.09372127e-04,\n",
       "          -1.05098751e-03,  1.89147089e-04,  9.90797998e-04,\n",
       "           4.13389906e-04, -4.06877574e-04, -1.18836318e-03,\n",
       "           6.87310181e-04,  1.10757491e-03, -1.59555042e-04,\n",
       "           3.47195164e-05, -1.20681971e-05,  6.24363602e-05,\n",
       "          -1.07021874e-03,  9.75335832e-04, -1.50149368e-04,\n",
       "          -4.48050385e-04,  4.91743383e-04, -2.92678218e-04,\n",
       "          -1.05475495e-03,  2.12506944e-04, -6.28461348e-05,\n",
       "          -3.82307917e-04, -3.09671712e-04,  2.07839141e-04,\n",
       "          -1.99291229e-04, -1.72181783e-04,  3.41598701e-04,\n",
       "           6.81391466e-05,  7.23117730e-04, -8.61647364e-04,\n",
       "          -9.52731934e-05, -1.02540746e-03, -1.72250904e-04,\n",
       "           2.77777785e-04, -6.51630340e-04, -1.32297748e-04,\n",
       "           7.62723037e-04, -1.53385874e-04, -3.72986484e-04,\n",
       "           4.35250142e-04,  4.32233501e-04, -8.20970105e-04,\n",
       "           9.89889144e-04, -7.59579598e-06,  3.19283543e-04,\n",
       "           1.39662021e-04,  5.18612331e-04,  3.45052540e-05,\n",
       "           7.86672626e-06,  2.37228713e-04,  7.14524882e-04,\n",
       "          -1.48743973e-04, -7.61135365e-04,  1.39866082e-04,\n",
       "           5.75390761e-04, -3.05595400e-04, -5.35166881e-04,\n",
       "          -2.16852655e-04,  1.07003341e-03, -2.37707980e-04,\n",
       "          -7.02004938e-04,  3.48770380e-04,  1.25897606e-03,\n",
       "           1.61364282e-04, -3.13641067e-04, -2.87220028e-04,\n",
       "          -3.79440055e-04, -2.80029955e-04,  9.76661569e-04,\n",
       "           6.97593205e-04,  4.37369104e-04, -1.39388291e-03,\n",
       "          -6.19628045e-05, -2.15514767e-04, -7.81149138e-05,\n",
       "           1.37936629e-04,  1.69096980e-04,  6.22034771e-04,\n",
       "           1.90264036e-04, -1.62931485e-03,  6.64547115e-05,\n",
       "          -3.41829698e-04, -6.80136844e-04, -8.10443424e-04,\n",
       "           1.25691411e-03, -2.20630493e-04, -6.11759169e-05,\n",
       "          -8.09037068e-04, -7.45530822e-04, -1.10025483e-03,\n",
       "           6.66367647e-04,  3.36484140e-04, -1.35511009e-03,\n",
       "           6.00685424e-04, -7.76448520e-04,  2.89177580e-04,\n",
       "          -1.42842147e-03, -7.24512211e-05, -6.97155134e-04,\n",
       "          -1.16323016e-03,  3.76730255e-04,  4.33170557e-04,\n",
       "           1.85371420e-04,  1.39217285e-04, -1.59412832e-03,\n",
       "          -4.10366192e-04, -4.75819797e-06,  1.06608181e-03,\n",
       "          -5.64093934e-04,  3.44564993e-04,  6.54774252e-04,\n",
       "          -2.04091601e-04, -3.68584238e-04,  2.74237915e-04,\n",
       "           3.13129094e-05, -1.12229027e-03,  2.94571044e-04,\n",
       "          -1.33533345e-03,  3.35383491e-04,  6.23079482e-04,\n",
       "           2.00525377e-04, -1.22295984e-03,  8.03587245e-05,\n",
       "          -5.63039968e-04, -5.78357896e-04,  2.59349152e-04,\n",
       "           8.84208537e-04,  1.17104246e-04,  8.13120801e-04,\n",
       "          -9.31946328e-04, -7.15542483e-05, -3.02171276e-04,\n",
       "           2.13661260e-05, -1.02818280e-03, -7.50655017e-04,\n",
       "           6.28433714e-04,  9.71626432e-05, -4.56502661e-04,\n",
       "           2.78149295e-04,  5.70180302e-04, -7.08338863e-04,\n",
       "           4.98858746e-04,  5.83392452e-04,  2.91323347e-04,\n",
       "           8.95289355e-04, -3.07503244e-04, -1.60668089e-04,\n",
       "           7.40266056e-04,  2.50022131e-04, -7.76420347e-04,\n",
       "           5.80746564e-04, -2.39486661e-04,  2.99032370e-04,\n",
       "           1.14847680e-04,  4.28476109e-04, -2.65873125e-04,\n",
       "          -7.49615079e-04, -1.60711526e-04, -1.13076065e-03,\n",
       "           8.87471251e-05,  1.44799997e-04,  5.29951940e-05,\n",
       "          -8.13111765e-05, -4.40698408e-04,  8.31631769e-04,\n",
       "          -1.22951122e-03,  8.77215818e-04, -1.71061707e-04,\n",
       "          -4.50776279e-04,  1.33162481e-03,  3.96646734e-04,\n",
       "          -2.72392549e-06,  1.27997505e-03,  4.49678861e-04,\n",
       "           1.31319626e-03,  1.07786292e-03, -4.73665714e-04,\n",
       "          -6.37494260e-04,  4.76867484e-04, -3.06840848e-05,\n",
       "           9.22408290e-05, -1.21879287e-03,  3.36939498e-04,\n",
       "           4.56419046e-04, -7.74407965e-07,  4.42687946e-04,\n",
       "          -1.66105485e-04, -5.58345462e-04, -3.77173797e-04,\n",
       "          -5.69955853e-04, -6.46882225e-04,  2.78175459e-04,\n",
       "           1.16425182e-03, -1.03866193e-03,  1.33869078e-04,\n",
       "          -2.84306327e-04, -4.03108803e-04,  3.20957624e-04,\n",
       "          -9.41734295e-04, -9.50088317e-04, -5.82836103e-04,\n",
       "          -3.00042855e-04,  5.05310658e-04,  1.71524080e-04,\n",
       "           8.70996737e-04, -6.69012661e-04,  4.61115415e-04,\n",
       "          -1.05551815e-04,  5.02221752e-04,  1.14637114e-04,\n",
       "          -9.33570496e-04,  2.99565407e-04, -9.88902408e-04,\n",
       "          -4.94340668e-04, -1.07289794e-04, -1.93760367e-04,\n",
       "          -3.97360855e-04, -3.73769115e-04,  4.92229825e-04,\n",
       "          -7.79376191e-04]], dtype=float32),\n",
       "  '_value_branch._model.0.bias': array([0.], dtype=float32),\n",
       "  'advantage_module.dueling_A_0._model.0.weight': array([[-0.03309743, -0.05849921, -0.0492792 , ..., -0.04058255,\n",
       "           0.09808841, -0.03112398],\n",
       "         [-0.10543036,  0.09655461, -0.09171208, ...,  0.00566818,\n",
       "           0.03342121,  0.08303615],\n",
       "         [ 0.0161515 ,  0.03097146,  0.05499988, ...,  0.0925319 ,\n",
       "           0.01278087,  0.09979913],\n",
       "         ...,\n",
       "         [-0.08337541,  0.03525072,  0.03377676, ...,  0.06452297,\n",
       "          -0.03077908, -0.10217507],\n",
       "         [-0.09210093,  0.06390715,  0.06528635, ..., -0.02536864,\n",
       "          -0.04826357,  0.03810249],\n",
       "         [ 0.06023473, -0.00039547, -0.10687473, ..., -0.04662364,\n",
       "           0.09761408, -0.05381475]], dtype=float32),\n",
       "  'advantage_module.dueling_A_0._model.0.bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.], dtype=float32),\n",
       "  'advantage_module.A._model.0.weight': array([[-7.72210583e-02, -2.18120050e-02,  3.50314076e-05,\n",
       "           1.22614108e-01,  2.22453438e-02, -1.29458308e-01,\n",
       "           5.76559156e-02,  5.11820130e-02, -1.35966226e-01,\n",
       "          -1.04604751e-01,  1.33530021e-01,  6.98208660e-02,\n",
       "           1.33566275e-01, -1.78856328e-02, -1.34397000e-01,\n",
       "          -1.44377381e-01,  5.15912473e-02, -1.41624078e-01,\n",
       "           1.39060169e-01,  1.07625954e-01,  1.44854277e-01,\n",
       "          -1.85861345e-02, -1.44913331e-01, -5.17814010e-02,\n",
       "           2.97777876e-02, -1.40920326e-01, -1.41499311e-01,\n",
       "           4.93938476e-02,  1.37498155e-01,  2.92291734e-02,\n",
       "           2.70075258e-02, -2.80074384e-02,  1.12845004e-01,\n",
       "          -3.18251885e-02, -2.06754562e-02,  1.51401371e-01,\n",
       "          -9.55241397e-02, -4.08535674e-02,  1.09924175e-01,\n",
       "           6.91373870e-02,  8.57445598e-02, -7.39060715e-02,\n",
       "           1.15531348e-01,  2.95086447e-02, -1.21238828e-01,\n",
       "          -2.43400484e-02, -1.31140456e-01, -4.89735827e-02,\n",
       "           2.84008924e-02, -4.71569486e-02,  4.93270569e-02,\n",
       "           7.52424821e-02, -5.62611334e-02,  1.51969641e-01,\n",
       "          -3.25661041e-02, -4.04984541e-02,  1.41667068e-01,\n",
       "          -1.48009405e-01, -4.01793346e-02,  1.07132211e-01,\n",
       "          -3.55065949e-02,  5.64064570e-02, -8.48994777e-02,\n",
       "          -5.70897236e-02,  5.26586063e-02, -4.06104364e-02,\n",
       "          -1.00761712e-01,  3.42685506e-02, -7.59583786e-02,\n",
       "           7.14055151e-02, -4.49853465e-02, -2.87807826e-02,\n",
       "           7.01050833e-02, -7.59962499e-02, -1.04684502e-01,\n",
       "          -2.03687558e-03,  1.10383734e-01, -4.36585508e-02,\n",
       "          -1.25370175e-01, -3.68791819e-02, -1.93594247e-02,\n",
       "          -1.25283189e-02, -4.26636189e-02, -1.22915216e-01,\n",
       "          -7.61670768e-02,  6.95311800e-02, -1.30853742e-01,\n",
       "           1.73187498e-02, -2.95124073e-02, -1.42459497e-01,\n",
       "          -7.58404732e-02,  1.42986611e-01, -5.57189547e-02,\n",
       "          -3.33932042e-02,  7.48999119e-02, -2.08605211e-02,\n",
       "           1.40674233e-01,  7.81731978e-02, -1.51637733e-01,\n",
       "          -6.78925067e-02, -1.05749078e-01, -8.85940641e-02,\n",
       "           1.20524481e-01, -1.12084433e-01, -1.15022421e-01,\n",
       "          -2.65638977e-02,  1.37614846e-01,  9.89484563e-02,\n",
       "           3.74898612e-02,  4.66492027e-02,  3.05355527e-02,\n",
       "          -8.36450234e-02,  4.05345224e-02, -7.38947317e-02,\n",
       "           2.14239154e-02, -1.36033863e-01, -8.76499861e-02,\n",
       "          -5.09325415e-02,  2.79169958e-02, -3.66358534e-02,\n",
       "           1.16075814e-01,  4.29318920e-02, -7.10128844e-02,\n",
       "          -1.91234946e-02,  4.52129319e-02,  8.89596716e-02,\n",
       "           1.10560305e-01, -3.94198782e-04,  5.10673560e-02,\n",
       "          -1.17555387e-01,  1.51745066e-01,  1.44613251e-01,\n",
       "          -1.06984124e-01, -4.82231416e-02,  1.41586810e-01,\n",
       "          -7.81415626e-02,  1.16410531e-01,  5.06865941e-02,\n",
       "          -1.50634557e-01,  3.49767804e-02, -2.81240586e-02,\n",
       "          -1.44404754e-01, -6.11737818e-02, -1.27136528e-01,\n",
       "           1.22208968e-01,  1.24929637e-01, -1.47180527e-01,\n",
       "          -3.45948711e-02,  1.23651072e-01,  1.41609803e-01,\n",
       "          -2.96607129e-02,  6.11260273e-02,  4.39118259e-02,\n",
       "           7.77079314e-02,  2.81989742e-02, -1.45153463e-01,\n",
       "          -3.13608199e-02, -9.10687372e-02, -1.98263228e-02,\n",
       "           8.86132121e-02, -5.36691360e-02,  1.51324362e-01,\n",
       "          -1.36883453e-01,  5.03807105e-02, -1.09887071e-01,\n",
       "           1.81610673e-03,  7.23728165e-02,  1.39192015e-01,\n",
       "           4.62305695e-02,  1.18297189e-01,  2.63693240e-02,\n",
       "           1.23126380e-01,  7.36244246e-02,  5.42406365e-02,\n",
       "          -1.16327599e-01,  1.15518406e-01, -8.19126666e-02,\n",
       "          -5.37191294e-02, -1.06898390e-01, -9.71803591e-02,\n",
       "           1.12265229e-01, -7.76575599e-03,  2.36133859e-03,\n",
       "           1.25306979e-01, -1.16055802e-01,  6.19284026e-02,\n",
       "          -5.38012981e-02,  7.43462294e-02,  9.68389735e-02,\n",
       "           7.46916682e-02,  1.30927131e-01, -6.59811199e-02,\n",
       "          -9.97778326e-02,  7.97481742e-03,  1.85042378e-02,\n",
       "           6.64498359e-02,  7.43918419e-02,  1.25225365e-01,\n",
       "          -3.19535360e-02, -4.25214954e-02, -2.79941130e-02,\n",
       "          -1.12284005e-01, -2.42360812e-02, -1.24018945e-01,\n",
       "           1.70817841e-02,  1.01828687e-01, -3.79745923e-02,\n",
       "          -1.25743270e-01, -4.35841419e-02, -1.06936179e-01,\n",
       "           1.31112233e-01, -1.14865661e-01,  8.27187002e-02,\n",
       "          -1.17556259e-01,  1.13995507e-01, -4.58769090e-02,\n",
       "           7.27157667e-02,  8.52506682e-02, -8.30049887e-02,\n",
       "          -4.98841815e-02, -4.37615179e-02, -3.14798206e-02,\n",
       "           1.40873879e-01,  1.19026691e-01, -2.37919427e-02,\n",
       "          -1.23735256e-01,  6.30659312e-02,  2.25909855e-02,\n",
       "           1.23502962e-01,  7.40946829e-02,  1.51213169e-01,\n",
       "          -1.41454171e-02, -7.22879916e-02,  1.00653723e-01,\n",
       "          -1.10901386e-01,  1.13811426e-01,  7.68346936e-02,\n",
       "           1.50290564e-01, -7.34474808e-02, -2.35209819e-02,\n",
       "           1.04661666e-01,  1.38433188e-01,  1.86039135e-02,\n",
       "           8.20790082e-02,  4.26361151e-02,  2.11217217e-02,\n",
       "          -3.43019105e-02,  1.12457290e-01, -1.20986104e-01,\n",
       "           3.06399390e-02,  5.51857762e-02, -1.44624949e-01,\n",
       "           1.18035428e-01, -7.79186115e-02,  6.06419109e-02,\n",
       "           2.16651708e-02],\n",
       "         [-3.13202962e-02,  1.25758290e-01, -1.38379365e-01,\n",
       "          -1.13146156e-01, -2.28939801e-02, -1.19072795e-02,\n",
       "          -7.12651387e-02,  1.31496429e-01,  9.03832167e-03,\n",
       "          -8.79176185e-02,  4.38852645e-02, -1.34857506e-01,\n",
       "          -1.34461701e-01,  1.05338991e-01, -1.26956582e-01,\n",
       "           1.08333565e-01, -3.58251520e-02,  1.14692666e-01,\n",
       "          -5.57850003e-02,  4.18975092e-02,  3.63560393e-02,\n",
       "          -8.89258534e-02, -5.03312424e-02, -3.03260740e-02,\n",
       "           5.56434914e-02, -1.14007585e-01, -5.08092307e-02,\n",
       "          -1.04375780e-02,  1.11402147e-01, -1.34597108e-01,\n",
       "           4.17322794e-04,  4.59655337e-02,  1.00847043e-01,\n",
       "          -1.05611973e-01,  1.47720024e-01, -5.04009984e-02,\n",
       "          -1.57774948e-02,  3.52502503e-02,  5.12394980e-02,\n",
       "          -1.25724196e-01, -4.75777797e-02, -8.32899436e-02,\n",
       "          -2.87965629e-02, -1.51146859e-01, -1.75085422e-02,\n",
       "          -1.03900373e-01, -2.10942160e-02, -7.31789023e-02,\n",
       "           1.02395331e-02, -1.43197805e-01, -3.87378670e-02,\n",
       "           1.23634219e-01, -2.28071380e-02,  3.13350209e-03,\n",
       "           1.34399429e-01,  8.02203044e-02,  2.12600827e-03,\n",
       "           9.92186219e-02,  4.08401862e-02,  1.37602150e-01,\n",
       "          -1.05812356e-01,  2.01458596e-02,  1.19814903e-01,\n",
       "          -1.59467626e-02,  1.37768239e-01, -3.92828993e-02,\n",
       "           7.36194775e-02,  8.56177062e-02, -2.61945128e-02,\n",
       "          -7.30845556e-02, -6.85771555e-02,  2.76794657e-02,\n",
       "          -1.00299157e-01,  1.50449632e-03, -1.09956667e-01,\n",
       "           1.44731641e-01, -1.31965697e-01, -7.65086338e-02,\n",
       "           9.27172303e-02, -1.13925159e-01, -1.29384967e-02,\n",
       "           1.98546648e-02,  8.59421715e-02, -1.08137667e-01,\n",
       "           1.09940432e-01, -7.04945698e-02,  8.09530541e-02,\n",
       "           3.45239900e-02, -1.43261150e-01, -1.81965530e-02,\n",
       "          -4.23686989e-02, -7.70027423e-03, -9.00279731e-02,\n",
       "          -1.04778975e-01, -5.32447398e-02, -6.51520938e-02,\n",
       "           8.63211527e-02, -8.90279710e-02,  4.21475656e-02,\n",
       "          -3.55503000e-02,  4.81295545e-04,  1.25294060e-01,\n",
       "          -5.13687311e-03, -1.44720510e-01, -1.16596231e-02,\n",
       "          -8.32393318e-02, -7.01779425e-02, -1.09919213e-01,\n",
       "          -5.35280816e-02, -1.12736598e-02, -4.45470251e-02,\n",
       "           9.37856436e-02, -1.38024297e-02,  8.50580782e-02,\n",
       "          -4.55702096e-02,  2.27625258e-02,  1.40158743e-01,\n",
       "           2.31141485e-02,  3.48858275e-02,  2.27151681e-02,\n",
       "           1.00714713e-01,  5.75352609e-02, -1.89378660e-03,\n",
       "          -6.88732564e-02,  1.14610009e-01,  1.13475800e-01,\n",
       "          -1.04158409e-01,  3.49284038e-02,  3.94530930e-02,\n",
       "          -5.93470596e-02, -1.30892873e-01,  8.97345990e-02,\n",
       "           9.59164873e-02, -4.45334278e-02, -1.30970329e-01,\n",
       "           2.14327499e-02, -1.09745003e-01,  7.56700933e-02,\n",
       "           6.48088902e-02, -1.39020175e-01,  1.40935317e-01,\n",
       "           9.13461521e-02, -1.20527856e-02, -1.32202774e-01,\n",
       "           2.01676926e-03,  1.41951740e-01, -3.73993441e-02,\n",
       "           7.53306895e-02,  7.38608390e-02,  1.79789849e-02,\n",
       "           5.62950559e-02, -7.25527033e-02, -2.83321012e-02,\n",
       "           8.16258565e-02, -1.52425826e-01, -7.72090033e-02,\n",
       "          -1.14749677e-01, -1.48248553e-01, -5.49541153e-02,\n",
       "          -1.64613798e-02, -6.92839995e-02, -7.40814283e-02,\n",
       "           8.32959265e-02, -6.52701333e-02, -9.25480872e-02,\n",
       "          -3.77445519e-02, -1.84519358e-05,  1.51104093e-01,\n",
       "           5.62240481e-02,  1.26091614e-01,  1.39141262e-01,\n",
       "          -4.58298810e-02, -1.48445696e-01,  3.28776762e-02,\n",
       "          -8.26988295e-02,  1.39132723e-01, -1.13569550e-01,\n",
       "           8.02764446e-02, -5.65341860e-03,  7.01239705e-02,\n",
       "           9.18563679e-02, -3.03596873e-02, -8.88657719e-02,\n",
       "           1.44534498e-01,  3.99154797e-02, -8.31945240e-02,\n",
       "          -1.10962138e-01, -1.01014853e-01, -9.46654305e-02,\n",
       "          -6.80289567e-02, -4.57421653e-02,  1.75038334e-02,\n",
       "          -1.00959428e-01,  7.84274340e-02, -3.91010866e-02,\n",
       "          -1.52396439e-02,  4.87551019e-02, -6.17652796e-02,\n",
       "           1.06819928e-01, -1.51751310e-01,  1.02404006e-01,\n",
       "           1.05628654e-01, -1.84269380e-02,  1.37469232e-01,\n",
       "          -5.12233004e-02, -1.55475829e-02, -2.82340609e-02,\n",
       "           1.46120964e-02, -1.00621127e-01,  1.40991703e-01,\n",
       "           1.96164064e-02, -1.43337414e-01,  9.78095978e-02,\n",
       "          -1.11595742e-01, -1.14734985e-01,  4.69963327e-02,\n",
       "          -9.54628550e-03,  9.23842005e-03, -1.25377223e-01,\n",
       "          -1.24959029e-01,  3.87661345e-02, -1.36227936e-01,\n",
       "           1.40063316e-01, -4.99689318e-02, -2.96173748e-02,\n",
       "           2.01615654e-02, -2.40155309e-02,  2.74467710e-02,\n",
       "           3.44981737e-02,  7.79357404e-02,  1.33128688e-01,\n",
       "           1.50470927e-01,  7.99620524e-02, -9.68397558e-02,\n",
       "           5.64412866e-03, -1.09042667e-01,  9.75040272e-02,\n",
       "           2.94276010e-02,  5.22159226e-02, -2.64473688e-02,\n",
       "           1.44478455e-01, -3.24278325e-02, -1.45092949e-01,\n",
       "          -3.56980413e-03, -7.57436827e-02,  2.85081118e-02,\n",
       "          -1.51070178e-01,  9.35631618e-02,  4.59077060e-02,\n",
       "           8.68439153e-02,  4.66063153e-03, -1.18327245e-01,\n",
       "          -9.53045562e-02, -7.39259943e-02,  1.02150932e-01,\n",
       "          -7.99644664e-02]], dtype=float32),\n",
       "  'advantage_module.A._model.0.bias': array([0., 0.], dtype=float32),\n",
       "  'value_module.dueling_V_0._model.0.weight': array([[ 0.0159375 , -0.05749275,  0.02198907, ...,  0.09631844,\n",
       "          -0.06680106,  0.01669768],\n",
       "         [-0.06193625, -0.06012095, -0.01984929, ..., -0.06275258,\n",
       "          -0.07924763,  0.04788116],\n",
       "         [ 0.03920498,  0.07427729, -0.05976544, ...,  0.00343719,\n",
       "           0.08949096,  0.07035244],\n",
       "         ...,\n",
       "         [-0.08997329,  0.07849376,  0.06802791, ..., -0.0795718 ,\n",
       "           0.10408007,  0.03440103],\n",
       "         [-0.1014169 ,  0.09865399,  0.00098226, ..., -0.1058418 ,\n",
       "          -0.10426784,  0.06712818],\n",
       "         [-0.02674496,  0.08375128,  0.00874946, ..., -0.01743698,\n",
       "          -0.06580482,  0.10753826]], dtype=float32),\n",
       "  'value_module.dueling_V_0._model.0.bias': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0.], dtype=float32),\n",
       "  'value_module.V._model.0.weight': array([[ 0.07164426, -0.06396254, -0.01851953, -0.11675906, -0.04072551,\n",
       "          -0.1456517 ,  0.116569  ,  0.14059268,  0.09432296, -0.06653806,\n",
       "          -0.00108779, -0.14623554, -0.10430323,  0.11784921, -0.10678689,\n",
       "           0.11505068,  0.0647375 , -0.06944644,  0.05972515,  0.02590343,\n",
       "          -0.06887634, -0.04102905, -0.13335727,  0.14025894, -0.0827982 ,\n",
       "          -0.09940594,  0.11776411, -0.02759833, -0.03642045, -0.05473594,\n",
       "          -0.03335642,  0.05612611,  0.08451729,  0.10528556, -0.05279594,\n",
       "           0.01659133,  0.13815647,  0.05309964, -0.11198562,  0.07589781,\n",
       "           0.13560401,  0.00238942,  0.06734657,  0.00894928,  0.13260825,\n",
       "          -0.12701288,  0.09792317, -0.13303858, -0.08490754,  0.03128735,\n",
       "          -0.01859126,  0.1428572 , -0.02061634, -0.04257831,  0.05763073,\n",
       "          -0.00742829,  0.13885812, -0.10263074,  0.06188205, -0.00925343,\n",
       "           0.06572016, -0.11274588, -0.01161742, -0.13515158,  0.13969675,\n",
       "          -0.09897296,  0.09556037, -0.06721342,  0.03859562, -0.07812652,\n",
       "           0.030173  , -0.09874432, -0.08037133, -0.04493149, -0.01321235,\n",
       "          -0.00109029, -0.1300664 ,  0.08515444, -0.00220402,  0.00610046,\n",
       "          -0.15110597, -0.01025898, -0.08643979,  0.09250289,  0.00413673,\n",
       "           0.05240828, -0.04600819,  0.04786495, -0.08686342,  0.01384015,\n",
       "          -0.05509291, -0.01617236,  0.07411527, -0.14653668, -0.0851432 ,\n",
       "          -0.09937274, -0.11684034,  0.14800428,  0.06137599,  0.09076145,\n",
       "           0.14329039,  0.03763509, -0.08104891,  0.14071915,  0.0008363 ,\n",
       "           0.0370441 ,  0.12932111, -0.08226515, -0.03474302, -0.14434128,\n",
       "           0.10355752,  0.06795319,  0.065594  , -0.09761461, -0.14160146,\n",
       "          -0.08463681,  0.04833252,  0.02922602,  0.04471362, -0.15062676,\n",
       "           0.1014784 ,  0.05078932, -0.07556067, -0.0997051 ,  0.1153229 ,\n",
       "          -0.01588785,  0.02426814,  0.01339817,  0.09083229, -0.05800109,\n",
       "           0.00193444,  0.05542728, -0.15200236,  0.11200654,  0.13829048,\n",
       "           0.03888367,  0.12420493, -0.14028092, -0.11906377,  0.10510638,\n",
       "          -0.04273048,  0.09098982,  0.1087064 ,  0.02056597,  0.02237772,\n",
       "           0.13045785,  0.01385441,  0.01015306,  0.09502601, -0.11392955,\n",
       "          -0.04209018, -0.11614631,  0.05414397,  0.0713054 , -0.09989936,\n",
       "           0.05847605,  0.12711744,  0.00463261, -0.08162154, -0.01718888,\n",
       "          -0.13913739, -0.136533  , -0.11710782,  0.05112408,  0.10593099,\n",
       "           0.11457392, -0.08708001, -0.06450874,  0.05613114, -0.01212902,\n",
       "           0.1323179 ,  0.12311479, -0.09952129, -0.0212396 , -0.10392147,\n",
       "           0.13147853, -0.02741824, -0.0601946 , -0.11414367, -0.1411702 ,\n",
       "          -0.11052713, -0.13847919, -0.06602421, -0.05073766, -0.05863124,\n",
       "          -0.00056711,  0.0451213 , -0.1042312 , -0.05030685,  0.04673038,\n",
       "           0.09495273, -0.01408481,  0.12727326,  0.10523275,  0.1204301 ,\n",
       "          -0.09767853,  0.13782462, -0.11469151,  0.03558854,  0.03939916,\n",
       "          -0.08364654, -0.14893965, -0.12750734, -0.06176701,  0.12943107,\n",
       "          -0.06151748, -0.10188892, -0.04238433, -0.07166249, -0.12439343,\n",
       "          -0.11075257,  0.00356964, -0.04083099, -0.09322806,  0.13662012,\n",
       "          -0.07642887, -0.02517113,  0.13776842,  0.14168848,  0.07718042,\n",
       "          -0.04865194, -0.09359312, -0.01827655, -0.11799578, -0.04155618,\n",
       "           0.05519038, -0.10518186,  0.02721306, -0.03330505,  0.10736783,\n",
       "          -0.06213033,  0.11938397, -0.11255849, -0.07784137,  0.09531118,\n",
       "          -0.01364157, -0.08284   ,  0.05034924, -0.14813751, -0.14057437,\n",
       "           0.01573829,  0.04954373, -0.12592767, -0.15085366, -0.04425241,\n",
       "          -0.05786411, -0.03077756,  0.14137259,  0.05756683,  0.07930145,\n",
       "          -0.0294378 ,  0.02414523,  0.1486755 ,  0.06853668,  0.15050048,\n",
       "          -0.05450553]], dtype=float32),\n",
       "  'value_module.V._model.0.bias': array([0.], dtype=float32)}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.rllib.algorithms.dqn import DQNConfig\n",
    "\n",
    "algo = DQNConfig().environment(env=\"CartPole-v1\").build()\n",
    "\n",
    "# Get weights of the default local policy\n",
    "algo.get_policy().get_weights()\n",
    "\n",
    "# Same as above\n",
    "algo.workers.local_worker().policy_map[\"default_policy\"].get_weights()\n",
    "\n",
    "# Get list of weights of each worker, including remote replicas\n",
    "algo.workers.foreach_worker(lambda worker: worker.get_policy().get_weights())\n",
    "\n",
    "# Same as above, but with index.\n",
    "algo.workers.foreach_worker_with_id(\n",
    "    lambda _id, worker: worker.get_policy().get_weights()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何访问模型状态，类似于访问策略状态，你可能想要获取正在训练的底层神经网络模型的引用。例如，你可能希望单独对其进行预训练，或以其他方式在RLlib之外更新其权重。这可以通过访问策略的模型来实现。\n",
    "\n",
    "简而言之，当你想要对正在训练的神经网络模型进行额外操作时，比如独立地进行预训练或者在RLlib之外更新权重时，你可以通过访问策略（policy）的模型来实现这一目的。这允许你直接操作模型，而无需依赖RLlib的训练循环。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40706/627519884.py:16: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  prep = get_preprocessor(env.observation_space)(env.observation_space)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    import gymnasium as gym\n",
    "\n",
    "    env = gym.make(\"CartPole-v1\")\n",
    "    obs, infos = env.reset()\n",
    "except Exception:\n",
    "    import gym\n",
    "\n",
    "    env = gym.make(\"PongNoFrameskip-v4\")\n",
    "    obs = env.reset()\n",
    "\n",
    "# RLlib uses preprocessors to implement transforms such as one-hot encoding\n",
    "# and flattening of tuple and dict observations.\n",
    "from ray.rllib.models.preprocessors import get_preprocessor\n",
    "\n",
    "prep = get_preprocessor(env.observation_space)(env.observation_space)\n",
    "# <ray.rllib.models.preprocessors.GenericPixelPreprocessor object at 0x7fc4d049de80>\n",
    "\n",
    "# Observations should be preprocessed prior to feeding into a model\n",
    "obs.shape\n",
    "# (210, 160, 3)\n",
    "prep.transform(obs).shape\n",
    "# (84, 84, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py:521: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2024-05-14 00:29:28,087\tWARNING deprecation.py:50 -- DeprecationWarning: `WorkerSet(num_workers=... OR local_worker=...)` has been deprecated. Use `EnvRunnerGroup(num_env_runners=... AND local_env_runner=...)` instead. This will raise an error in the future!\n",
      "2024-05-14 00:29:28,091\tWARNING deprecation.py:50 -- DeprecationWarning: `max_num_worker_restarts` has been deprecated. Use `AlgorithmConfig.max_num_env_runner_restarts` instead. This will raise an error in the future!\n",
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/models/catalog.py:895: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  prep = cls(observation_space, options)\n",
      "/simulation/jianghaoning/anaconda3/envs/multi_agent/lib/python3.11/site-packages/ray/rllib/connectors/agent/obs_preproc.py:37: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  self._preprocessor = get_preprocessor(obs_space)(\n",
      "2024-05-14 00:29:28,847\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.algorithms.callbacks import MemoryTrackingCallbacks\n",
    "# Construct a generic config object, specifying values within different\n",
    "# sub-categories, e.g. \"training\".\n",
    "config = (PPOConfig().training(gamma=0.9, lr=0.01)\n",
    "        .environment(env=\"CartPole-v1\")\n",
    "        .resources(num_gpus=0)\n",
    "        .env_runners(num_env_runners=0)\n",
    "        .callbacks(MemoryTrackingCallbacks)\n",
    "    )\n",
    "# A config object can be used to construct the respective Algorithm.\n",
    "rllib_algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ray.tune.tuner.Tuner at 0x7f35d68cad50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray import tune\n",
    "# In combination with a tune.grid_search:\n",
    "config = PPOConfig()\n",
    "config.training(lr=tune.grid_search([0.01, 0.001]))\n",
    "# Use `to_dict()` method to get the legacy plain python config dict\n",
    "# for usage with `tune.Tuner().fit()`.\n",
    "tune.Tuner(\"PPO\", param_space=config.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Parameters:\n",
    "gamma (float) : The discount factor of the MDP.\n",
    "lr (float) : The learning rate of the policy.\n",
    "grad_clip (float) : The gradient clipping value.\n",
    "grad_clip_by(str) : The gradient clipping method.\n",
    "train_batch_size_per_learner (int) : The batch size for training.\n",
    "train_batch_size (int) : The total batch size for training.\n",
    "model(dict) : The model configuration.\n",
    "optimizer(dict) : The optimizer configuration.\n",
    "max_request_in_flight_per_sampler_worker (int) : The maximum number of requests in flight per sampler worker.\n",
    "learner_class\n",
    "learner_connector\n",
    "add_default_connectors_to_learner_pipeline\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Parameters:\n",
    "env(str) : The environment name.\n",
    "env_config\n",
    "observation_space\n",
    "action_space\n",
    "env_task_fn\n",
    "render_env\n",
    "clip_rewards \n",
    "normalize_actions\n",
    "clip_actions\n",
    "is_atari \n",
    "action_mask_key \n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
